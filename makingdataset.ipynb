{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e86ff4d",
   "metadata": {},
   "source": [
    "anomaly_dataset/normal/      # Only forest images\n",
    "\n",
    "anomaly_dataset/anomaly/     # All other categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ca67180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy as np\n",
    "random.seed(2)\n",
    "np.random.seed(2)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e206d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da99cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base directory of the dataset\n",
    "base_dir = \"archive/seg_test/seg_test\"\n",
    "# Define classes\n",
    "normal_class = \"forest\"\n",
    "anomaly_classes = [\"buildings\", \"glacier\", \"mountain\", \"sea\", \"street\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33383cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete:\n",
      "  Train → normal=284, anomaly=0\n",
      "   Val  → normal=95, anomaly=20\n",
      "   Test → normal=95, anomaly=20\n"
     ]
    }
   ],
   "source": [
    "# 1) Paths & classes\n",
    "base_dir        = Path(\"archive/seg_test/seg_test\")\n",
    "normal_class    = \"forest\"\n",
    "anomaly_classes = [\"buildings\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "output_dir      = Path(\"split_anomaly_dataset\")\n",
    "\n",
    "# 2) Helper to copy files into a folder\n",
    "def make_split(file_list, target_dir):\n",
    "    target_dir = Path(target_dir)\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for f in file_list:\n",
    "        shutil.copy(f, target_dir / f.name)\n",
    "\n",
    "# 3) Gather all file paths\n",
    "normal_files   = list((base_dir / normal_class).glob(\"*.jpg\"))\n",
    "anomaly_files  = []\n",
    "for cls in anomaly_classes:\n",
    "    anomaly_files += list((base_dir / cls).glob(\"*.jpg\"))\n",
    "\n",
    "# 4) Split normals: 60% train, 20% val, 20% test\n",
    "n_train = int(len(normal_files) * 0.6)\n",
    "train_norm, temp_norm = train_test_split(normal_files, train_size=n_train, random_state=42)\n",
    "val_norm, test_norm   = train_test_split(temp_norm, test_size=0.5,     random_state=42)\n",
    "\n",
    "# 5) Split anomalies: 50% val, 50% test (no anomalies in train)\n",
    "val_anom, test_anom = train_test_split(anomaly_files, test_size=0.5, random_state=42)\n",
    "\n",
    "# ↓ only take *up to* N anomalies in each split ↓\n",
    "MAX_ANOM_VAL  = 20\n",
    "MAX_ANOM_TEST = 20\n",
    "\n",
    "val_anom  = random.sample(val_anom,  min(len(val_anom),  MAX_ANOM_VAL))\n",
    "test_anom = random.sample(test_anom, min(len(test_anom), MAX_ANOM_TEST))\n",
    "\n",
    "# 6) Copy into folder structure (unchanged)\n",
    "for split, normals, anoms in [\n",
    "    (\"train\", train_norm, []),\n",
    "    (\"val\",   val_norm,   val_anom),\n",
    "    (\"test\",  test_norm,  test_anom),\n",
    "]:\n",
    "    make_split(normals, output_dir / split / \"normal\")\n",
    "    make_split(anoms,    output_dir / split / \"anomaly\")\n",
    "\n",
    "print(\"Dataset split complete:\")\n",
    "print(f\"  Train → normal={len(train_norm)}, anomaly=0\")\n",
    "print(f\"   Val  → normal={len(val_norm)}, anomaly={len(val_anom)}\")\n",
    "print(f\"   Test → normal={len(test_norm)}, anomaly={len(test_anom)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b83d9c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly dataset created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Define classes\n",
    "normal_class = \"forest\"\n",
    "anomaly_classes = [\"buildings\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "\n",
    "# Output directories\n",
    "output_dir = \"anomaly_dataset\"\n",
    "normal_dir = os.path.join(output_dir, \"normal\")\n",
    "anomaly_dir = os.path.join(output_dir, \"anomaly\")\n",
    "\n",
    "# Create output folders\n",
    "os.makedirs(normal_dir, exist_ok=True)\n",
    "os.makedirs(anomaly_dir, exist_ok=True)\n",
    "\n",
    "# Copy normal class images\n",
    "for img_name in os.listdir(os.path.join(base_dir, normal_class)):\n",
    "    src = os.path.join(base_dir, normal_class, img_name)\n",
    "    dst = os.path.join(normal_dir, img_name)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "# Copy anomaly class images\n",
    "for cls in anomaly_classes:\n",
    "    class_path = os.path.join(base_dir, cls)\n",
    "    for img_name in os.listdir(class_path):\n",
    "        src = os.path.join(class_path, img_name)\n",
    "        dst = os.path.join(anomaly_dir, f\"{cls}_{img_name}\")\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "print(\"Anomaly dataset created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b522f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "\n",
    "# # Parameters\n",
    "# data_dir = \"anomaly_dataset\"\n",
    "# output_dir = \"split_anomaly_dataset\"\n",
    "# c = 0.1  # Proportion of anomalies in each set\n",
    "\n",
    "# # Read and shuffle image file paths\n",
    "# normal_images = [os.path.join(data_dir, \"normal\", img) for img in os.listdir(os.path.join(data_dir, \"normal\"))]\n",
    "# anomaly_images = [os.path.join(data_dir, \"anomaly\", img) for img in os.listdir(os.path.join(data_dir, \"anomaly\"))]\n",
    "\n",
    "# random.shuffle(normal_images)\n",
    "# random.shuffle(anomaly_images)\n",
    "\n",
    "# # Decide how many images go into each split\n",
    "# total_samples_per_split = min(len(normal_images) + len(anomaly_images), 20000) // 2\n",
    "# num_anomalies = int(c * total_samples_per_split)\n",
    "# num_normals = total_samples_per_split - num_anomalies\n",
    "\n",
    "# # Ensure we don't request more images than we have\n",
    "# num_normals = min(num_normals, len(normal_images) // 2)\n",
    "# num_anomalies = min(num_anomalies, len(anomaly_images) // 2)\n",
    "\n",
    "# # Now build splits\n",
    "# train_normal = normal_images[:num_normals]\n",
    "# test_normal = normal_images[num_normals:num_normals*2]\n",
    "\n",
    "# train_anomaly = anomaly_images[:num_anomalies]\n",
    "# test_anomaly = anomaly_images[num_anomalies:num_anomalies*2]\n",
    "\n",
    "# # Helper to copy files\n",
    "# def copy_files(file_list, target_dir):\n",
    "#     os.makedirs(target_dir, exist_ok=True)\n",
    "#     for f in file_list:\n",
    "#         shutil.copy(f, os.path.join(target_dir, os.path.basename(f)))\n",
    "\n",
    "# # Copy all files to split folders\n",
    "# copy_files(train_normal, os.path.join(output_dir, \"train\", \"normal\"))\n",
    "# copy_files(train_anomaly, os.path.join(output_dir, \"train\", \"anomaly\"))\n",
    "# copy_files(test_normal, os.path.join(output_dir, \"test\", \"normal\"))\n",
    "# copy_files(test_anomaly, os.path.join(output_dir, \"test\", \"anomaly\"))\n",
    "\n",
    "# print(f\"Train/Test split complete.\")\n",
    "# print(f\"Train -> Normal: {len(train_normal)}, Anomaly: {len(train_anomaly)}\")\n",
    "# print(f\"Test  -> Normal: {len(test_normal)}, Anomaly: {len(test_anomaly)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d7331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
